# Citing Marx - Experiment 2: Traditional NLP

This is work associated with the CDH project [Citing Marx](https://cdh.princeton.edu/projects/citing-marx/)

## Traditional NLP experiments

This branch contains code and data for preliminary experiments using
traditional NLP approaches and out-of-the-box software to identify
title mentions and quotations in sample text content from the Citing Marx project.

### Preliminary conclusions

- lemmatized search is decent, but doesn't find variants with OCR errors, typos, hyphenation (without additional interventions)
- Flair worked better than Stanza for our use cases; Flair NER does identify some instances of titles with OCR errors ("Eanifests", "Mauifests") but does not find all titles
  - Available off-the-shelf NER models for German only have 4 categories (PER, LOC, ORG, MISC) compared to the richer 18-category ontology available for English.
  - Fine-grained NER annotation datasets exist for German but these may not include a relevant category (e.g., work of art) and likely require building our own NER pipeline.


### Contents

- `data/`
  - `annotation/`: snapshot of annotation data exported from Recogito; CSV files
  - `direct_quotes_subset.csv`: subset of direct quote annotations from experiment 1
  - `title_mentions_subset.csv`: subset of title mention annotations from experiment 1
  - `compiled_title_mentions.csv`: restructured title annotation data generated by `compile_title_annotations.py` script with Yes/No/Maybe values for mentions of Kapital and Manifesto
  - `title_searchphrases.csv` : CSV file with search phrases and corresponding titles
  - `candidate-mentions/` : files generated by `remarx-candidate-mentions` lemmatized search
    - `title_mentions.csv`: results from several title phrases run across three text files; refer to `title_searchphrases.csv` for mapping phrases to canonical titles
    - `concept_mentions.csv`: results from a few concept phrases run against all 25 _Die Neue Zeit_ texts
   - `candidate_ner.csv` : CSV file with spans tagged by NER with Flair, as possible candidates for title mentions; one entity per row
   - `title_mentions_flair_ner.csv`: CSV file with preliminary Flair NER results; multiple entities by type for each sentence id
   - `title_mentions_sent_results.csv`: CSV combining compiled title mentions data (with yes/no/maybe for each title), lemmatized search results for title candidates, and Flair NER spans
- `notebooks/`: marimo notebooks for data exploration, experimentation, and review
- `src/remarx/`: python package with utility code and scripts
   - `build_sentence_corpus.py`: script to parse a directory of text files into a JSONL corpus of sentences; uses Stanza for sentence splitting
   - `candidate_mentions.py`: script to run lemmatized search on directory of text files and generate a CSV of matching sentences
   - `get_ner_spans.py`: script to run Flair NER on a CSV of candidate sentences and generate a CSV of identified entities, one entity per row
   - `polar_utils.py`: utility method sfor loading and manipulating data related to title mentions and candidates
   - `run_xslt.py`: script to run an XSLT transform on an XML file using SaxonCHE
- `tei-stylesheets/`: copies of TEI-consorsium XSLT files for basic tei-to-text conversion


Some notebooks have been saved as static HTML snapshots; they can be found
in the `notebooks/__marimo__/` folder.


## Development Instructions

### Developer setup and installation
- **Recommended:** create a python virtual environment with your tool of choice (virtualenv, conda, etc); use python 3.12 or higher

- Install the local checked out version of this package in editable mode (`-e`), including all python dependencies and optional dependencies for development and testing:

```sh
pip install -e ".[dev]"
```

- This repository uses [pre-commit](https://pre-commit.com/) for python code linting and consistent formatting. Run this command to initialize and install pre-commit hooks:

```sh
pre-commit install
```