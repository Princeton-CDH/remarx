# Citing Marx - Experiment 2: Traditional NLP

This is work associated with the CDH project [Citing Marx](https://cdh.princeton.edu/projects/citing-marx/)

## Traditional NLP experiments

This branch contains code and data for preliminary experiments using
traditional NLP approaches and out-of-the-box software to identify
title mentions and quotations in sample text content from the Citing Marx project.

### Preliminary conclusions

- Title and concept phrase detection:
  - lemmatized search is decent, but doesn't find variants with OCR errors, typos, hyphenation (without additional interventions)
  - Flair worked better than Stanza for our use cases; Flair NER does identify some instances of titles with OCR errors ("Eanifests", "Mauifests") but finds a very limited number of title mentions
    - Available off-the-shelf NER models for German only have 4 categories (PER, LOC, ORG, MISC) compared to the richer 18-category ontology available for English.
    - Fine-grained NER annotation datasets exist for German but these may not include a relevant category (e.g., work of art) and likely require building our own NER pipeline.
- Quotation detection 
  - seq2seq-quotation-attribution : some overlap with manual annotation (often detected as multiple different quotations), but also detected many irrelevant quotations (not a perfect fit for our content or our question)
  - rule-based quotation detection : ran as a baseline to compare with seq2seq results and manual annotation; finds many non-relevant quotations (as well as some title mentions) and is brittle when quotes are not closed or span page breaks


### Contents

- `data/`
  - `annotation/`: snapshot of annotation data exported from Recogito; CSV files
  - `direct_quotes_subset.csv`: subset of direct quote annotations from experiment 1
  - `title_mentions_subset.csv`: subset of title mention annotations from experiment 1
  - `compiled_title_mentions.csv`: restructured title annotation data generated by `compile_title_annotations.py` script with Yes/No/Maybe values for mentions of Kapital and Manifesto
  - `title_searchphrases.csv` : CSV file with search phrases and corresponding titles
  - [`candidate-mentions/`](data/candidate_mentions) : files generated by and documentation related to `candidate_mentions.py`  lemmatized search; see the README for this folder
    - `title_mentions.csv`: results from several title phrases run across three text files; refer to `title_searchphrases.csv` for mapping phrases to canonical titles
    - `concept_mentions.csv`: results from a few concept phrases run against all 25 _Die Neue Zeit_ texts
    - `candidate-mentions.slurm` sample slurm batch file for running this command; more details in the folder README file
   - `candidate_ner.csv` : CSV file with spans tagged by NER with Flair generated by `get_ner_spans.py` script for the sentences in `title_mentions.csv`; one NER entity per row
   - `title_mentions_flair_ner.csv`: CSV file with preliminary Flair NER results; multiple entities by type for each sentence
   - `title_mentions_sent_results.csv`: CSV combining compiled title mentions data (with yes/no/maybe for each title), lemmatized search results for title candidates, and Flair NER spans. Generated with methods in `remarx.polars_utils` and `evaluate-candidate-sentences` notebook
 - `seq2seq/1896-97aCLEAN_parts_output/`: files related to test of seq2seq-quotation-attribution tool run on text chunked from 1896-97aCLEAN.txt 
    - `quotes.csv` : CSV file of quotes detected by seq2seq-quotation-attribution
    - `input_offsets.csv` : CSV file of input offsets to map seq2seq character indices back to the full text file; generated and used by seq2seq-review notebook
- `notebooks/`: marimo notebooks for data exploration, experimentation, and review
- `src/remarx/`: python package with utility code and scripts
   - `build_sentence_corpus.py`: script to parse a directory of text files into a JSONL corpus of sentences; uses Stanza for sentence splitting
   - `candidate_mentions.py`: script to run lemmatized search on directory of text files and generate a CSV of matching sentences
   - `compile_title_annotations.py`: script to compile and restructure title mention annotation data from Recogito to provide Yes/No/Maybe values for the two titles in current scope
   - `get_ner_spans.py`: script to run Flair NER on a CSV of candidate sentences and generate a CSV of identified entities, one entity per row
   - `polar_utils.py`: utility methods for loading and manipulating data related to title mentions and candidates
   - `run_xslt.py`: script to run an XSLT transform on an XML file using SaxonCHE
- `tei-stylesheets/`: copies of TEI-consorsium XSLT files for basic tei-to-text conversion


Some notebooks have been saved as static HTML snapshots; they can be found
in the `notebooks/__marimo__/` folder.


## Development Instructions

### Developer setup and installation
- **Recommended:** create a python virtual environment with your tool of choice (virtualenv, conda, etc); use python 3.12 or higher

- Install the local checked out version of this package in editable mode (`-e`), including all python dependencies and optional dependencies for development and testing:

```sh
pip install -e ".[dev]"
```

- This repository uses [pre-commit](https://pre-commit.com/) for python code linting and consistent formatting. Run this command to initialize and install pre-commit hooks:

```sh
pre-commit install
```
