"""
Utility polar functions for loading and manipulating
title mention-related data.
"""

import csv
from collections import defaultdict

import polars as pl


def load_title_phrases(
    filename: str = "data/title_searchphrases.csv",
) -> dict[str, list[str]]:
    """
    Load title phrases from file. Returns a dictionary mapping
    a title (e.g., "Kapital") to a list of its search phrases
    used for identifying candidate sentences.
    """
    title_phrases = defaultdict(list)
    with open(filename, encoding="utf-8-sig", newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            title_phrases[row["title"]].append(row["phrase"])
    return title_phrases


def load_title_annotations(
    filename: str = "data/compiled_title_mentions.csv",
) -> pl.DataFrame:
    """
    Load title mentions annotations from a CSV file and prepare a dataframe for
    combination with other data. Expects a CSV file generated by
    `compile_title_annotations` script. The resulting dataframe prepends "anno_"
    to each column name (e.g., "uiud" --> "anno_uiud")
    """
    annotations_df = (
        pl.read_csv(filename)
        .rename(lambda col_name: f"anno_{col_name}")
        .rename(
            {
                "anno_start_idx": "anno_start",
                "anno_end_idx": "anno_end",
                "anno_span_text": "anno_text",
            }
        )
    )
    return annotations_df


def load_flair_ner(filename: str = "data/candidate_ner.csv") -> pl.DataFrame:
    """
    Load flair NER entities from a CSV file and prepare a dataframe for combination
    with other data. Expects a CSV file generated by `get_ner_spans` script. The
    resulting dataframe prepends "flair_".
    """
    flair_df = pl.read_csv(filename).rename(lambda col_name: f"flair_{col_name}")
    return flair_df


def load_candidate_sentences(
    filename: str, title_phrases: dict[str, str]
) -> pl.DataFrame:
    """
    Load candidate sentences from a CSV file and prepare a dataframe for
    combination with other data. Expects a CSV file generated by
    `candidate_mentions` script. The resulting dataframe contains the following
    additional columns:
        * sent_idx: sentence-level identifier ([file]:[sent_idx])
        * sent_start: starting character index of sentence (same as char_idx)
        * sent_end: ending character index of sentence
        * phrase_list: list of sentences matching search phrases
        * kapital_candidate: indicates if sent is a candidate for Das Kapital
        * manifest_candidate: indicates if sent is a candidate for the Communist Manifesto
    """
    # Load initial data
    df = pl.read_csv(filename)

    # Initial field munging
    df = df.with_columns(
        # Create sentence id
        pl.concat_str(
            pl.col("file"),
            pl.col("sent_idx"),
            separator=":",
        ).alias("sent_id"),
        pl.col("char_idx").alias("sent_start"),
        # Create phrase list from phrases column
        pl.col("phrases").str.split(" | ").alias("phrase_list"),
    )

    # Construct additional fields, dependent on previous step
    df = df.with_columns(
        # Compute ending index
        (pl.col("sent_start") + pl.col("sentence").str.len_chars()).alias("sent_end"),
        # Determine if sentence is a title candidate by check for a title's phrases
        ## Determine if sentence is a candidate for Das Kapital
        (
            (
                pl.col("phrase_list").list.set_intersection(title_phrases["Kapital"])
            ).list.len()
            > 0
        ).alias("kapital_candidate"),
        ## Determine if sentence is a candidate for the Communist Manifesto
        (
            (
                pl.col("phrase_list").list.set_intersection(title_phrases["Manifesto"])
            ).list.len()
            > 0
        ).alias("manifest_candidate"),
    ).select(
        # Reorder columns
        [
            "sent_id",
            "file",
            "sent_idx",
            "char_idx",
            "sentence",
            "phrases",
            "phrase_list",
            "lem_phrases",
            "sent_start",
            "sent_end",
            "kapital_candidate",
            "manifest_candidate",
        ]
    )

    return df


def join_candidates_annotation(
    candidate_sentences_df: pl.DataFrame,
    annotations_df: pl.DataFrame,
) -> pl.DataFrame:
    """
    Adds title mention annotations to candidate sentences dataframe. Expects the
    title mention annotations to have been loaded using `load_title_annotations`
    script and candidate sentences to have been loaded using
    `load_candidate_sentences` method. For a given sentence without an annotation,
    the following values are set:
        * anno_uiud: "N/A"
        * anno_start: None
        * anno_end: None
        * anno_mentions_kapital: "No"
        * anno_mentions_manifest: "No"
    """
    # Sentences with annotations
    annotated_sents = (
        # Find sentences that overlap with annotations
        candidate_sentences_df.join_where(
            annotations_df,
            pl.col("file") == pl.col("anno_file"),
            pl.col("sent_start") < pl.col("anno_end"),
            pl.col("anno_start") < pl.col("sent_end"),
        ).drop("anno_file")
    )

    # Sentences without annotations
    unannotated_sents = candidate_sentences_df.filter(
        ~pl.col("sent_id").is_in(annotated_sents.get_column("sent_id").to_list())
    ).with_columns(
        # add annotation-related columns
        pl.lit("N/A").alias("anno_uuid"),
        pl.lit(None).alias("anno_start"),
        pl.lit(None).alias("anno_end"),
        pl.lit(None).alias("anno_text"),
        pl.lit("No").alias("anno_mentions_kapital"),
        pl.lit("No").alias("anno_mentions_manifest"),
    )

    return annotated_sents.vstack(unannotated_sents).sort(["file", "sent_idx"])


def join_candidates_ner(
    candidate_sentences_df: pl.DataFrame,
    flair_ner_df: pl.DataFrame,
) -> pl.DataFrame:
    """
    Adds flair NER annotations to candidate sentences dataframe. Expects the flair
    NER annotations to have been loaded using `load_flair_ner` and candidate sentences
    to have been lodaded using `load_candidate_sentences` method. For a given
    sentence without an annotation, teh following values are set:
        * flair_ner_spans: None
        * flair_contains_band: false
        * flair_contains_kapital: false
        * flair_contains_manifest: false
    """
    # Sentences with flair results
    flair_sents = (
        candidate_sentences_df.join_where(
            flair_ner_df,
            pl.col("file") == pl.col("flair_file"),
            pl.col("sent_idx") == pl.col("flair_sent_idx"),
        )
        .group_by(candidate_sentences_df.columns)
        .agg(
            pl.concat_str(
                [pl.col("flair_ner_tag"), pl.format('"{}"', pl.col("flair_span_text"))],
                separator=" : ",
            ).alias("flair_ner_spans"),
            pl.col("flair_contains_band").sum() > 0,
            pl.col("flair_contains_kapital").sum() > 0,
            pl.col("flair_contains_manifest").sum() > 0,
        )
        .with_columns(
            pl.col("flair_ner_spans").list.join(" | ").alias("flair_ner_spans"),
        )
    )

    # Sentences without flair results
    other_sents = candidate_sentences_df.filter(
        ~pl.col("sent_id").is_in(flair_sents.get_column("sent_id").to_list())
    ).with_columns(
        # add flair-related columns
        pl.lit(None).alias("flair_ner_spans"),
        pl.lit(False).alias("flair_contains_band"),
        pl.lit(False).alias("flair_contains_kapital"),
        pl.lit(False).alias("flair_contains_manifest"),
    )

    return flair_sents.vstack(other_sents).sort(["file", "sent_idx"])
