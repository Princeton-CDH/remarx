{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Test Structured Output / Structured response\n",
    "\n",
    "Some models and APIs have support for structured output, even defining and enforcing a schema and types for the generated output. Is that usable enough for us to use it? Which models support it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Testing with AI Sandbox\n",
    "\n",
    "This is the [OpenAI post](https://openai.com/index/introducing-structured-outputs-in-the-api/) I started with.\n",
    "\n",
    "Then I found Azure OpenAI documentation on [structured outputs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/structured-outputs?tabs=python-secure%2Cdotnet-entra-id&pivots=programming-language-python).\n",
    "\n",
    "Documentation includes the list of supported models; this includes version dates, but I'm not sure we have access to that information for the AI Sandbox models.\n",
    "\n",
    "It _also_ lists the API version, which might be why I couldn't get this to work:\n",
    "\n",
    "> Support for structured outputs was first added in API version `2024-08-01-preview`. It is available in the latest preview APIs as well as the latest GA API: `2024-10-21`.\n",
    "\n",
    "As of April 2025, the API version to use with AI Sandbox is **2025-03-01-preview**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "* * *\n",
    "\n",
    "Use a page of text from the quote data subset for testing.\n",
    "\n",
    "This is the last entry in the quote data subset file. The expected quote based on annotation data:\n",
    "\n",
    "> „die Arbeiter¬ klasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some variables with sample content and prompts to use in a few different calls\n",
    "\n",
    "page_text = \"\"\"\n",
    "Das demokrattsche Prinzip und seine Anwendung. 25 liegt das auf der Hand. Wir mögen bis an den Eingang zur Werkstatt gleich¬ sein, aber in der Werkstatt sind wir es nicht mehr. Da muß der Ingenieur anordnett und der Schlosser, Dreher &c. ausführen, da kann der Heizer nicht nach seinem Kopf verfahren und den Kessel abstellen, wenn es ihm paßt. So¬ in jedem großen Wirthschaftsunternehmen, so aber auch in der Wirthschaft selbst. Ueberall, wo Kooporation ist, ist Arbeitstheilung, und wo Arbeitstheilung ist, ist Verschiedenheit der Funktionen, wo Verschiedenheit der Funktionen Verschieden¬ heit der Vollmachten. Diese sind heute vielfach übertrieben, weil das überkommene Nr C Klassenmoment hineinspielt, weil der Hert Ingenieur in der Regel der he¬ schenden Gesellschaftsklasse angehört und der Dreher der beherrschten. Diese Ueber¬ treibung, der Absolutismus in der Werkstatt &c., läßt sich beseitigen und wird im Lautfe der Entwicklung beseitigt werden. Aber eben nur die Uebertreibung, die Differenzirung wird darum doch bleiben. Sie wird nur ihre Schärfe dadurch¬ verlieren, daß die Menschen selbst vielseitiger ausgebildet und vielseitiger beschäftigt, werden, so daß die Unterordnung wechselt. Die Sozialdemokratie kann sich nicht außerhalb der Gesellschaft stellen, der sie lebt, kann also auch in ihren Reihen die thatsächlichen Unterschiede nicht ignoriren. Es wird immer ihr Bestreben sein müssen, für jeden Posten den möglichst geeigneten Mann herauszusuchen, und das trifft auch für die Vertretung im Parlament 3u. In Uebrigen sind für die Verwirklichung der Demokratie noch wichtigere, Aufgaben zu erfüllen als die Verbesserung der Stimmenzählungsmethoden. Sehr viel wichtiger ist die Demokratisirung der Verwaltungen, die bessere Vertheilung der Verwaltungsaufgaben und die Demokratisirung des Wahlrechts zu den Ver¬ waltungskörpern. Ob die Arbetterklasse statt durch 45 durch 95 Abgeordnete, im Reichstag vertreten ist, das würde an den Dingen vorderhand wenig ändern, denn die Gesetze würden kaum viel anders ausfallen als jetzt. Aber noch ist der Eintritt in die meisten Landtage, in die Provinzial- und Kreisvertretungen. den Arbeitern verschlossen, und in den Gemeindevertretungen nur mit großen Einschränkungen möglich. Das möchte Manchem hente als gleichgiltig erscheinen gegenüber den großen Erfolgen bei den Reichstagswahlen. Ohue diese zu ver¬ kleinern müssen wir jedoch daran erinnern, daß diese Erfolge zum Theil das Produkt außergewöhnlicher Umstände sind, und daß im Uebrigen „die Arbeiter¬ klasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann“ Wir erkennen also an, daß innerhalb gewisser Greuzen und unter bestimmten. erhältnissen — sehr vorgeschrittene politische Einrichtungen - has Proportional¬ wahlsystem wünschbar sein mag. In Deutschland, wo noch so viele Elementar¬ bedingungen demokratischen Lebens fehlen, ist es ein Luxusartikel, für den Kraft¬ einzusetzen sie wichtigeren Arbeiten entziehen hieße. — Beispiele dafür giebt es schon heute. So kommen bei sogenannten freiwilligen Feuerwehren Subordinationsverhältnisse vor, die den bürgerlichen Lebensstellungen der be¬ treffenden Personen direkt widersprechen. Desgleichen beim Heer, und sie würden dort noch hüufiger sein, wenn nicht in Deutschland bei den Heereseinrichtungen dem ständischen Prinzip Rechnung getragen würde. NEW_DOCUMENT\n",
    "Zinner,+etal._1896_15:01_388_Notizen,Feuilleton\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = \"You are a helpful research assistant fluent in German. You help researchers identify important content in text from German scholarship.  Identify and return any passages in this text provided by the user that quote from works by Karl Marx.\"\n",
    "\n",
    "user_prompt = page_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import marimo as mo\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# define a simple model with the fields we want returned\n",
    "# previously tried including start/end indices; model returns numbers but they are useless\n",
    "class Quote(BaseModel):\n",
    "    text: str\n",
    "    title: Optional[str]\n",
    "\n",
    "\n",
    "# Both APIs supports nested models; we need to support multiple quotes on a page, so return a list of quotes\n",
    "# using the Quote model defined above\n",
    "class QuoteList(BaseModel):\n",
    "    quotes: list[Quote]\n",
    "\n",
    "\n",
    "# initialize an api client for AI sandbox\n",
    "\n",
    "SANDBOX_ENDPOINT = \"https://api-ai-sandbox.princeton.edu/\"\n",
    "SANDBOX_API_VERSION = \"2025-03-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AI_SANDBOX_KEY\"),\n",
    "    api_version=SANDBOX_API_VERSION,\n",
    "    azure_endpoint=SANDBOX_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### gpt-4o\n",
    "\n",
    "For structured response with gpt-4o, we use openai + pydantic to pass in the response model to the `tools` option.\n",
    "\n",
    "If you try passing it in as a response format (`response_format=Quote`), you get a BadRequest response with this error message:\n",
    "```\n",
    "response_format value as json_schema is enabled only for api versions 2024-08-01-preview and later\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    # model=\"gpt-4o-mini\",\n",
    "    # model=\"Meta-Llama-3-1-8B-Instruct-nwxcg\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    # response_format=QuoteList.model_json_schema(),  # not supported by our API version or not being passed correctly\n",
    "    tools=[\n",
    "        openai.pydantic_function_tool(QuoteList),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Dump the full response as json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BPCDd1oRG1MPxzSYvV0KGrvpG9REI\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_I2CzFKfaWNb3dfpZtpJSF6C6\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"quotes\\\": [{\\\"text\\\": \\\"„die Arbeiterklasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann“\\\", \\\"title\\\": null}]}\",\n",
      "              \"name\": \"QuoteList\",\n",
      "              \"parsed_arguments\": {\n",
      "                \"quotes\": [\n",
      "                  {\n",
      "                    \"text\": \"„die Arbeiterklasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann“\",\n",
      "                    \"title\": null\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"call_EKWDyHs6Yii0L2oQbHr3GbZA\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"quotes\\\": [{\\\"text\\\": \\\"„die Arbeiterklasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann“\\\", \\\"title\\\": null}]}\",\n",
      "              \"name\": \"QuoteList\",\n",
      "              \"parsed_arguments\": {\n",
      "                \"quotes\": [\n",
      "                  {\n",
      "                    \"text\": \"„die Arbeiterklasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann“\",\n",
      "                    \"title\": null\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ],\n",
      "        \"parsed\": null\n",
      "      },\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1745344869,\n",
      "  \"model\": \"gpt-4o-2024-05-13\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": \"fp_65792305e4\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 111,\n",
      "    \"prompt_tokens\": 900,\n",
      "    \"total_tokens\": 1011,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# here is the full response as json\n",
    "print(gpt4o_completion.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Output the parsed response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">Returned 1 quote(s).</span>\n",
       "<span class=\"paragraph\"><strong>quotation:</strong></span>\n",
       "<span class=\"paragraph\">„die Arbeiterklasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann“</span>\n",
       "<span class=\"paragraph\"><strong>title:</strong>\n",
       "None</span></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this parsed_arguments field is actually a Quote instance!\n",
    "gpt4o_parsed = (\n",
    "    gpt4o_completion.choices[0].message.tool_calls[0].function.parsed_arguments\n",
    ")\n",
    "\n",
    "mo.md(f\"\"\"\n",
    "Returned {len(gpt4o_parsed.quotes)} quote(s).\n",
    "\n",
    "**quotation:**\n",
    "\n",
    "{gpt4o_parsed.quotes[0].text}\n",
    "\n",
    "\n",
    "**title:**\n",
    "{gpt4o_parsed.quotes[0].title}\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**GPT4o** : ✅ quote  ⛔title\n",
    "\n",
    "Correctly returns the full text of the expected quote and only that quote.\n",
    "\n",
    "It looks like it is using the article title (?) at the top of the page text as the title.  The tag in the annotation data is \"Manifest der Kommunistischen Partei\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4omini_completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # model=\"Meta-Llama-3-1-8B-Instruct-nwxcg\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    # response_format=Quote,  # not supported by our API version\n",
    "    tools=[\n",
    "        openai.pydantic_function_tool(QuoteList),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BPCDf2QRPDsNQAsRmzFFrmfbraLDX\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_WJsG9MMKVOOIAslovGwbKidc\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"quotes\\\":[{\\\"text\\\":\\\"die Arbeiter¬ klasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann\\\",\\\"title\\\":null}]}\",\n",
      "              \"name\": \"QuoteList\",\n",
      "              \"parsed_arguments\": {\n",
      "                \"quotes\": [\n",
      "                  {\n",
      "                    \"text\": \"die Arbeiter¬ klasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann\",\n",
      "                    \"title\": null\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ],\n",
      "        \"parsed\": null\n",
      "      },\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1745344871,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": \"fp_7a53abb7a2\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 47,\n",
      "    \"prompt_tokens\": 900,\n",
      "    \"total_tokens\": 947,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(gpt4omini_completion.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">Returned 1 quote(s).</span>\n",
       "<span class=\"paragraph\"><strong>quotation:</strong></span>\n",
       "<span class=\"paragraph\">die Arbeiter¬ klasse nicht die fertige Staatsmaschine einfach in Besitz nehmen und für ihre eigenen Zwecke in Bewegung setzen kann</span>\n",
       "<span class=\"paragraph\"><strong>title:</strong>\n",
       "None</span></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this parsed_arguments field is actually a Quote instance!\n",
    "gpt4omini_parsed = (\n",
    "    gpt4omini_completion.choices[0]\n",
    "    .message.tool_calls[0]\n",
    "    .function.parsed_arguments\n",
    ")\n",
    "\n",
    "mo.md(f\"\"\"\n",
    "Returned {len(gpt4omini_parsed.quotes)} quote(s).\n",
    "\n",
    "**quotation:**\n",
    "\n",
    "{gpt4omini_parsed.quotes[0].text}\n",
    "\n",
    "\n",
    "**title:**\n",
    "{gpt4omini_parsed.quotes[0].title}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**GPT4o-mini** : ⛔/✅quote  ⛔title\n",
    "\n",
    "On a previous run it returned incorrect quote: a different set of text surrounded by „“.  This time it returned the correct quote.\n",
    "\n",
    "Like GPT4o, it returns the text at the beginning of the page as a title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnkX",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### ⛔ llama 3.1 8B instruct\n",
    "\n",
    "I couldn't get this one to work. When I try the `tools` parameters that works for gpt4o and our version of the API:\n",
    "```python\n",
    "tools=[\n",
    "        openai.pydantic_function_tool(Quote),\n",
    "    ],\n",
    "```\n",
    "I get an \"invalid input error.\" The details of the message indicate it's complaining about required fields (maybe required fields for the quote object).\n",
    "\n",
    "When I try specifying it as a response format, I get different errors. Passing in the class:\n",
    "```python\n",
    "response_format=Quote\n",
    "```\n",
    "Results in\n",
    "> Response format was json_schema but must be either 'text' or 'json_object'.\n",
    "\n",
    "When I try passing the json schema for my model, I get the same error:\n",
    "```python\n",
    "response_format=Quote.model_json_schema()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "disabled": true
     }
    }
   },
   "outputs": [],
   "source": [
    "llama_completion = client.beta.chat.completions.parse(\n",
    "    model=\"Meta-Llama-3-1-8B-Instruct-nwxcg\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    # not sure the right syntax for this one\n",
    "    response_format=Quote.model_json_schema(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Testing with local Ollama server\n",
    "\n",
    "Testing with the Ollama python client based on a [blog post about structured outputs](https://ollama.com/blog/structured-outputs).\n",
    "\n",
    "Setup requires installing [ollama](https://ollama.com/), and then start the server and download (pull) and run models.\n",
    "\n",
    "```console\n",
    "pip install ollama\n",
    "ollama serve\n",
    "ollama run llama3.2\n",
    "ollama run mixtral\n",
    "```\n",
    "\n",
    "You can use `ollama ps` to check which models are running and how much longer they will be running; default keepalive time is 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "\n",
    "def identify_quotes(page_text, model):\n",
    "    response = chat(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        model=model,\n",
    "        format=QuoteList.model_json_schema(),\n",
    "    )\n",
    "\n",
    "    return QuoteList.model_validate_json(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulZA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try getting from llama3.2\n",
    "llama_quotes = identify_quotes(page_text, \"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">Identified 1 quote(s)</span>\n",
       "<span class=\"paragraph\"><strong>quotation:</strong>  <br />\n",
       "Klassenmoment</span>\n",
       "<span class=\"paragraph\"><strong>title:</strong>\n",
       "Quelle: Marx, Karl (1867): Das Kapital. Kritik der politischen Ökonomie. Erster Teil. Herausgegeben von Friedrich Engels. Stuttgart: J.H.W. Dietz. S. 91.</span></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_quotes_md = [f\"Identified {len(llama_quotes.quotes)} quote(s)\"]\n",
    "\n",
    "for llama_q in llama_quotes.quotes:\n",
    "    llama_quotes_md.append(f\"\"\"**quotation:**    \n",
    "{llama_q.text}\n",
    "\n",
    "**title:**\n",
    "{llama_q.title}\"\"\")\n",
    "\n",
    "mo.md(\"\\n\\n\\n\".join(llama_quotes_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBYS",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**llama3.2** : ⛔/0️⃣ quote  ⛔/0️⃣title\n",
    "\n",
    "On some runs it returned an incorrect quote and incorrect title. It was returning some text from the third line of the first paragraph. When I adjusted the prompt to move the instructions to the system prompt, it didn't return anything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aLJB",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### mixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHfw",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixtral_quotes = identify_quotes(page_text, \"mixtral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">Identified 1 quote(s)</span>\n",
       "<span class=\"paragraph\"><strong>quotation:</strong>  <br />\n",
       "Wir erkennen also an, daß innerhalb gewisser Grenzen und unter bestimmten, erhaltnissen — sehr vorgeschrittene politische Einrichtungen - has Proportional-wahlsystem wünschbar sein mag.</span>\n",
       "<span class=\"paragraph\"><strong>title:</strong>\n",
       "Zinner, etal. 1896 15:01 388 Notizen, Feuilleton</span></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mixtral_quotes_md = [f\"Identified {len(mixtral_quotes.quotes)} quote(s)\"]\n",
    "\n",
    "for mixtral_q in mixtral_quotes.quotes:\n",
    "    mixtral_quotes_md.append(f\"\"\"**quotation:**    \n",
    "{mixtral_q.text}\n",
    "\n",
    "**title:**\n",
    "{mixtral_q.title}\"\"\")\n",
    "\n",
    "mo.md(\"\\n\\n\\n\".join(mixtral_quotes_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AjVT",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**mixtral** : ⛔quote  ⛔title\n",
    "\n",
    "Returning multiple things, all of them wrong. On a previous run, before I modified the prompt, it returned some text near the beginning of the first paragraph (also incorrect)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pHFh",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Ollama server is [compatible with openai chat completions API](https://ollama.com/blog/openai-compatibility), including structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NCOB",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "ollama_oaiclient = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\",  # required, but unused\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aqbW",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<span class=\"codehilite\"><div class=\"highlight\"><pre><span></span><span class=\"gt\">Traceback (most recent call last):</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/marimo/_runtime/executor.py&quot;</span>, line <span class=\"m\">141</span>, in <span class=\"n\">execute_cell</span>\n",
      "<span class=\"w\">    </span><span class=\"n\">exec</span><span class=\"p\">(</span><span class=\"n\">cell</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">,</span> <span class=\"n\">glbls</span><span class=\"p\">)</span>\n",
      "<span class=\"w\">    </span><span class=\"pm\">~~~~^^^^^^^^^^^^^^^^^^</span>\n",
      "  File <span class=\"nb\">&quot;/var/folders/mb/6qm4h4yx3yqdy2bv2sjyp4z00000gp/T/marimo_22610/__marimo__cell_aqbW_.py&quot;</span>, line <span class=\"m\">1</span>, in <span class=\"n\">&lt;module&gt;</span>\n",
      "<span class=\"w\">    </span><span class=\"n\">ollama_completion</span> <span class=\"o\">=</span> <span class=\"n\">ollama_oaiclient</span><span class=\"o\">.</span><span class=\"n\">beta</span><span class=\"o\">.</span><span class=\"n\">chat</span><span class=\"o\">.</span><span class=\"n\">completions</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"s2\">&quot;llama3.2&quot;</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">    </span><span class=\"o\">...&lt;</span><span class=\"mi\">7</span> <span class=\"n\">lines</span><span class=\"o\">&gt;...</span>\n",
      "<span class=\"w\">    </span>    <span class=\"p\">],</span>\n",
      "<span class=\"w\">    </span><span class=\"p\">)</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/resources/beta/chat/completions.py&quot;</span>, line <span class=\"m\">158</span>, in <span class=\"n\">parse</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_post</span><span class=\"p\">(</span>\n",
      "<span class=\"w\">           </span><span class=\"pm\">~~~~~~~~~~^</span>\n",
      "<span class=\"w\">    </span>    <span class=\"s2\">&quot;/chat/completions&quot;</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"o\">...&lt;</span><span class=\"mi\">46</span> <span class=\"n\">lines</span><span class=\"o\">&gt;...</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">stream</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"p\">)</span>\n",
      "<span class=\"w\">    </span><span class=\"pm\">^</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/_base_client.py&quot;</span>, line <span class=\"m\">1276</span>, in <span class=\"n\">post</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">ResponseT</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">request</span><span class=\"p\">(</span><span class=\"n\">cast_to</span><span class=\"p\">,</span> <span class=\"n\">opts</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"o\">=</span><span class=\"n\">stream</span><span class=\"p\">,</span> <span class=\"n\">stream_cls</span><span class=\"o\">=</span><span class=\"n\">stream_cls</span><span class=\"p\">))</span>\n",
      "<span class=\"w\">                           </span><span class=\"pm\">~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/_base_client.py&quot;</span>, line <span class=\"m\">949</span>, in <span class=\"n\">request</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_request</span><span class=\"p\">(</span>\n",
      "<span class=\"w\">           </span><span class=\"pm\">~~~~~~~~~~~~~^</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">cast_to</span><span class=\"o\">=</span><span class=\"n\">cast_to</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"o\">...&lt;</span><span class=\"mi\">3</span> <span class=\"n\">lines</span><span class=\"o\">&gt;...</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">retries_taken</span><span class=\"o\">=</span><span class=\"n\">retries_taken</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"p\">)</span>\n",
      "<span class=\"w\">    </span><span class=\"pm\">^</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/_base_client.py&quot;</span>, line <span class=\"m\">1059</span>, in <span class=\"n\">_request</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_process_response</span><span class=\"p\">(</span>\n",
      "<span class=\"w\">           </span><span class=\"pm\">~~~~~~~~~~~~~~~~~~~~~~^</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">cast_to</span><span class=\"o\">=</span><span class=\"n\">cast_to</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"o\">...&lt;</span><span class=\"mi\">4</span> <span class=\"n\">lines</span><span class=\"o\">&gt;...</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">retries_taken</span><span class=\"o\">=</span><span class=\"n\">retries_taken</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"p\">)</span>\n",
      "<span class=\"w\">    </span><span class=\"pm\">^</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/_base_client.py&quot;</span>, line <span class=\"m\">1158</span>, in <span class=\"n\">_process_response</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">api_response</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">()</span>\n",
      "<span class=\"w\">           </span><span class=\"pm\">~~~~~~~~~~~~~~~~~~^^</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/_response.py&quot;</span>, line <span class=\"m\">325</span>, in <span class=\"n\">parse</span>\n",
      "<span class=\"w\">    </span><span class=\"n\">parsed</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_options</span><span class=\"o\">.</span><span class=\"n\">post_parser</span><span class=\"p\">(</span><span class=\"n\">parsed</span><span class=\"p\">)</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/resources/beta/chat/completions.py&quot;</span>, line <span class=\"m\">152</span>, in <span class=\"n\">parser</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">_parse_chat_completion</span><span class=\"p\">(</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">response_format</span><span class=\"o\">=</span><span class=\"n\">response_format</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">chat_completion</span><span class=\"o\">=</span><span class=\"n\">raw_completion</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">input_tools</span><span class=\"o\">=</span><span class=\"n\">tools</span><span class=\"p\">,</span>\n",
      "<span class=\"w\">    </span><span class=\"p\">)</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/lib/_parsing/_completions.py&quot;</span>, line <span class=\"m\">90</span>, in <span class=\"n\">parse_chat_completion</span>\n",
      "<span class=\"w\">    </span><span class=\"s2\">&quot;parsed_arguments&quot;</span><span class=\"p\">:</span> <span class=\"n\">parse_function_tool_arguments</span><span class=\"p\">(</span>\n",
      "<span class=\"w\">                        </span><span class=\"pm\">~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">input_tools</span><span class=\"o\">=</span><span class=\"n\">input_tools</span><span class=\"p\">,</span> <span class=\"n\">function</span><span class=\"o\">=</span><span class=\"n\">tool_call</span><span class=\"o\">.</span><span class=\"n\">function</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"p\">),</span>\n",
      "<span class=\"w\">    </span><span class=\"pm\">^</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/lib/_parsing/_completions.py&quot;</span>, line <span class=\"m\">145</span>, in <span class=\"n\">parse_function_tool_arguments</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">model_parse_json</span><span class=\"p\">(</span><span class=\"n\">input_fn</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">function</span><span class=\"o\">.</span><span class=\"n\">arguments</span><span class=\"p\">)</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/openai/_compat.py&quot;</span>, line <span class=\"m\">169</span>, in <span class=\"n\">model_parse_json</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">model_validate_json</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n",
      "<span class=\"w\">           </span><span class=\"pm\">~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^</span>\n",
      "  File <span class=\"nb\">&quot;/Users/rkoeser/workarea/env/marx/lib/python3.13/site-packages/pydantic/main.py&quot;</span>, line <span class=\"m\">744</span>, in <span class=\"n\">model_validate_json</span>\n",
      "<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"bp\">cls</span><span class=\"o\">.</span><span class=\"n\">__pydantic_validator__</span><span class=\"o\">.</span><span class=\"n\">validate_json</span><span class=\"p\">(</span>\n",
      "<span class=\"w\">           </span><span class=\"pm\">~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^</span>\n",
      "<span class=\"w\">    </span>    <span class=\"n\">json_data</span><span class=\"p\">,</span> <span class=\"n\">strict</span><span class=\"o\">=</span><span class=\"n\">strict</span><span class=\"p\">,</span> <span class=\"n\">context</span><span class=\"o\">=</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">by_alias</span><span class=\"o\">=</span><span class=\"n\">by_alias</span><span class=\"p\">,</span> <span class=\"n\">by_name</span><span class=\"o\">=</span><span class=\"n\">by_name</span>\n",
      "<span class=\"w\">        </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n",
      "<span class=\"w\">    </span><span class=\"p\">)</span>\n",
      "<span class=\"w\">    </span><span class=\"pm\">^</span>\n",
      "<span class=\"gr\">pydantic_core._pydantic_core.ValidationError</span>: <span class=\"n\">1 validation error for QuoteList</span>\n",
      "<span class=\"x\">quotes</span>\n",
      "<span class=\"x\">  Input should be a valid array [type=list_type, input_value=&#39;[&quot;Das demokrättische Pr...tung im Parlament 3u.&quot;]&#39;, input_type=str]</span>\n",
      "<span class=\"x\">    For further information visit https://errors.pydantic.dev/2.11/v/list_type</span>\n",
      "</pre></div>\n",
      "</span>"
     ]
    }
   ],
   "source": [
    "ollama_completion = ollama_oaiclient.beta.chat.completions.parse(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    # response_format=QuoteList.model_json_schema(),  # this seems to be ignored\n",
    "    tools=[\n",
    "        openai.pydantic_function_tool(QuoteList),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TRpd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ollama_completion.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TXez",
   "metadata": {},
   "source": [
    "The API is not exactly compatible, since the `tool_calls` is null. The content looks like a json dump of the QuoteList object with associated quotes, so it is enforcing the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dNNg",
   "metadata": {},
   "source": [
    "## CSV output\n",
    "\n",
    "CSV output might be a simpler way to get structured output, but may be less reliable.\n",
    "\n",
    "Testing with the last paragraph of page text from the quote subset (page index 661, two quotes).\n",
    "\n",
    "The expected quote from this paragraph:\n",
    "> „Zur Lösung dieses Widerspruchs\" fährt er fort, „bedarf es noch vieler Mittelglieder.“ Er versprach, diese Lösung später zu geben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCnT",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### ollama - llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlCL",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='font-size: 12px'>ChatResponse(model=&#x27;llama3.2&#x27;, created_at=&#x27;2025-04-22T18:01:42.871681Z&#x27;, done=True, done_reason=&#x27;stop&#x27;, total_duration=2507974667, load_duration=11408583, prompt_eval_count=396, prompt_eval_duration=217995875, eval_count=227, eval_duration=2277371250, message=Message(role=&#x27;assistant&#x27;, content=&#x27;Unfortunately, I couldn\\&#x27;t find any direct quotes of Karl Marx\\&#x27;s works in the provided paragraph. However, I can suggest some possible sources where you might find relevant information.\\n\\nThat being said, I did manage to extract a reference to a Marxist concept:\\n\\n1.,,&quot;daß dies Gesetz offenbar, aller auf den Augenschein gegründeten Erfahrung widerspricht&quot;,,,Marx, Kapital (Erstes Buch), S. 123\\n(Note: This is not a direct quote from Marx\\&#x27;s work, but rather an paraphrase of his ideas)\\n\\nIf you would like me to analyze the paragraph further or try to find relevant quotes, please let me know!\\n\\nEdit:\\n\\nAfter re-reading the paragraph, I found another possible reference:\\n\\n1.,&quot;Zur Lösung dieses Widerspruchs&quot;,,,Marx, Kapital (Erstes Buch), S. 123\\nAgain, this is not a direct quote from Marx\\&#x27;s work, but rather an attribution of his ideas.\\n\\nIf you have any further information or context about the paragraph, I may be able to help you better.&#x27;, images=None, tool_calls=None))</pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_prompt = \"\"\"Identify any direct quotes of Karl Marx's works in this paragraph, along with the work title if known. Also include the source for the title (context reference or otherwise). Return the results in this CSV format:\n",
    "number,quote,title,title_source\n",
    "\n",
    "Nachdem Marx im ersten Bande des „Kapital“, Kapitel X, das Gesetz, des Mehrwerths festgestellt hatte, fügte er sogleich hinzu, „daß dies Gesetz offenbar, aller auf den Augenschein gegründeten Erfahrung widerspricht\". „Zur Lösung dieses Widerspruchs\" fährt er fort, „bedarf es noch vieler Mittelglieder.“ Er versprach, diese Lösung später zu geben. Die wenigen Nationalökonomen, denen diese Stelle auffiel, setzten ihre Zuversicht auf diesen ihnen unlösbar scheinenden Widerspruch, der nach ihrer Ansicht die Theorie zu Falle bringen mußte. Mehrere hofften, daß der Theore¬ tiker des Werthes dort mit seiner Dialektik und seinem Kommumnismus scheitern. werde, denen, wie sie überzeugt waren, jede wissenschaftliche Grundlage fehle. Herr Loria, der geniale Entdecker so mancher schon von Marx entdeckten Theorien, ging so weit, zu behaupten, daß derselbe, um seine Ohumacht nicht einzugestehen, sich entschlossen hätte, die beiden Bände, welche sein ökonomisches\n",
    "\"\"\"\n",
    "\n",
    "csvresponse = chat(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": csv_prompt},\n",
    "    ],\n",
    "    model=\"llama3.2\",\n",
    ")\n",
    "csvresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kqZH",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, I couldn't find any direct quotes of Karl Marx's works in the provided paragraph. However, I can suggest some possible sources where you might find relevant information.\n",
      "\n",
      "That being said, I did manage to extract a reference to a Marxist concept:\n",
      "\n",
      "1.,,\"daß dies Gesetz offenbar, aller auf den Augenschein gegründeten Erfahrung widerspricht\",,,Marx, Kapital (Erstes Buch), S. 123\n",
      "(Note: This is not a direct quote from Marx's work, but rather an paraphrase of his ideas)\n",
      "\n",
      "If you would like me to analyze the paragraph further or try to find relevant quotes, please let me know!\n",
      "\n",
      "Edit:\n",
      "\n",
      "After re-reading the paragraph, I found another possible reference:\n",
      "\n",
      "1.,\"Zur Lösung dieses Widerspruchs\",,,Marx, Kapital (Erstes Buch), S. 123\n",
      "Again, this is not a direct quote from Marx's work, but rather an attribution of his ideas.\n",
      "\n",
      "If you have any further information or context about the paragraph, I may be able to help you better.\n"
     ]
    }
   ],
   "source": [
    "print(csvresponse.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wAgl",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### AI sandbox - gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rEll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ai sandbox gpt-4o with csv output\n",
    "\n",
    "gpt4o_csv_completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": csv_prompt},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dGlV",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number,quote,title,title_source\n",
      "1,\"daß dies Gesetz offenbar, aller auf den Augenschein gegründeten Erfahrung widerspricht\",\"Kapital\",\"Kapital, Kapitel X, Band 1\"\n",
      "2,\"Zur Lösung dieses Widerspruchs\",\"Kapital\",\"Kapital, Kapitel X, Band 1\"\n"
     ]
    }
   ],
   "source": [
    "print(gpt4o_csv_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SdmI",
   "metadata": {},
   "source": [
    "The second quote found is the expected one, but the full content is not returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lgWD",
   "metadata": {},
   "source": [
    "### AI sandbox - gpt-4o-min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yOPj",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4omini_csv_completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": csv_prompt},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fwwy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number,quote,title,title_source\n",
      "1,\"daß dies Gesetz offenbar, aller auf den Augenschein gegründeten Erfahrung widerspricht\",\"Das Kapital, Band I\",\"Kapital, Erste Auflage\"\n",
      "2,\"Zur Lösung dieses Widerspruchs\",\"Das Kapital, Band I\",\"Kapital, Erste Auflage\"\n"
     ]
    }
   ],
   "source": [
    "print(gpt4omini_csv_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LJZf",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The second quote is the expected response. It doesn't return the full text, but returns more of the quote than GPT4o did. They seem to be stopping at punctuation - likely because this quote as annotated includes text _between_ and _after_ the parts of the quote.\n",
    "\n",
    "> „Zur Lösung dieses Widerspruchs\" fährt er fort, „bedarf es noch vieler Mittelglieder.“ Er versprach, diese Lösung später zu geben.\n",
    "\n",
    "From google translate:\n",
    "\n",
    "> \"To resolve this contradiction,\" he continues, \"many intermediate links are still needed.\" He promised to provide this solution later."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
